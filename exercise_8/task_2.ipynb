{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/workspaces/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:83: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.MNIST(\n",
    "   root=\"./data\",\n",
    "   download=True,\n",
    "   train=True,\n",
    "   transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "   root=\"./data\",\n",
    "   download=True,\n",
    "   train=False,\n",
    "   transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "amount = 500\n",
    "batch_size = 100\n",
    "epochs = 1\n",
    "workers = 8\n",
    "\n",
    "shuffled_ind = np.random.permutation(np.arange(len(train_set)))\n",
    "\n",
    "calibration_set = torch.utils.data.Subset(train_set, shuffled_ind[:amount])\n",
    "train_set = torch.utils.data.Subset(train_set, shuffled_ind[amount:])\n",
    "\n",
    "# create Dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train_set, shuffle=True, batch_size=batch_size, num_workers=8)\n",
    "calibration_loader = torch.utils.data.DataLoader(calibration_set, shuffle=True, batch_size=batch_size, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, shuffle=False, batch_size=batch_size, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bad Net\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "from torch.nn import functional\n",
    "import torch\n",
    "\n",
    "class BadNet(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BadNet, self).__init__()        \n",
    "        self.conv1 = torch.nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.AvgPool2d(kernel_size=(2, 2), stride=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=16, \n",
    "                out_channels=32, \n",
    "                kernel_size=5, \n",
    "                stride=1),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.AvgPool2d(kernel_size=(2, 2), stride=2),                \n",
    "        )\n",
    "        self.f1 = nn.Sequential(\n",
    "            nn.Linear(in_features=(32 * 4 * 4), out_features=512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(in_features=512, out_features=10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)        \n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        x = self.f1(x)\n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "\n",
    "        loss = nn.functional.cross_entropy(out, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "        test_loss = nn.functional.cross_entropy(out, y)\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "\n",
    "    def backward(self, loss, optimizer, optimizer_idx):\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "        validiation_loss = nn.functional.cross_entropy(out, y)\n",
    "        self.log(\"validation_loss\", validiation_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "bad_net = BadNet()\n",
    "trainer = pl.Trainer(max_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/workspaces/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | conv1 | Sequential | 416   \n",
      "1 | conv2 | Sequential | 12.8 K\n",
      "2 | f1    | Sequential | 262 K \n",
      "3 | out   | Sequential | 5.1 K \n",
      "-------------------------------------\n",
      "281 K     Trainable params\n",
      "0         Non-trainable params\n",
      "281 K     Total params\n",
      "1.124     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3686b7e19a154d2ca7f01d575c754584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = trainer.fit(bad_net, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def get_logits(model, dataloader):\n",
    "    logits = []\n",
    "    labels = []\n",
    "    model.eval()\n",
    "\n",
    "    for x, y in tqdm(dataloader):\n",
    "        with torch.no_grad():\n",
    "            logits.append(model(x))\n",
    "            labels.append(y)\n",
    "    \n",
    "    return torch.cat(logits), torch.cat(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prediction_sets(model, calibration_loader, test_loader, alpha=0.3):\n",
    "    calib_logits, calib_y = get_logits(model, calibration_loader)\n",
    "    n = len(calibration_loader)\n",
    "\n",
    "    probs = calib_logits.softmax(dim=1)\n",
    "\n",
    "    scores = 1 - torch.gather(probs, 1, calib_y.unsqueeze(dim=1))\n",
    "    qhat = torch.quantile(scores, np.ceil((n + 1) * (1 - alpha))/n)\n",
    "\n",
    "    test_logits, test_y = get_logits(model, test_loader)\n",
    "    smx = test_logits.softmax(dim=1)\n",
    "\n",
    "    return (smx > (1 - qhat)).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9fa5b3d20bd47dfaa73ae3d3d869246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e33f0dbb1c24ee6a7ff5837216427d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    7],\n",
      "        [   1,    2],\n",
      "        [   2,    1],\n",
      "        ...,\n",
      "        [9998,    5],\n",
      "        [9998,    8],\n",
      "        [9999,    6]])\n"
     ]
    }
   ],
   "source": [
    "prediction_sets = calc_prediction_sets(bad_net, calibration_loader, test_loader)\n",
    "print(prediction_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[[   0    7]\n",
      " [   1    2]\n",
      " [   2    1]\n",
      " ...\n",
      " [9998    5]\n",
      " [9998    8]\n",
      " [9999    6]]\n"
     ]
    }
   ],
   "source": [
    "nps = prediction_sets.detach().numpy()\n",
    "\n",
    "x0 = nps[::, 0]\n",
    "x1 = nps[::, 1]\n",
    "print(np.unique(x0).shape)\n",
    "print(np.unique(x1))\n",
    "print(nps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b15c47a3642161de9e36b10a1d071c67059fa2fd42cde25fc64e01c54ad71872"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
