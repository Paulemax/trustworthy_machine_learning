{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "Part a) Describe Domain adversarial training (dat) in your own words:\n",
    "\n",
    "- The goal of DAT is to train the Domain predictor and the label predictor at the same time\n",
    "- To achieve this goal we need to achieve two objectives\n",
    "    - minimize the error of the label predictor \n",
    "    - maximize the error of the domain predictor\n",
    "- These goals don't mix well together... \n",
    "    - therefore dann introduces an ANN architecture to solve this issue.\n",
    "    - the ANN is split in three \"models\", the feature extractor,     \n",
    "```mermaid\n",
    "graph TD;\n",
    "    FeatureExtractor -> LabelPredictor;\n",
    "    FeatureExtractor -> DomainPredictor;\n",
    "```\n",
    "gradient reversal layer to achieve this\n",
    "\n",
    "\n",
    "\n",
    "adept python for density estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import mnist_m\n",
    "import gradientreversal\n",
    "\n",
    "# constants\n",
    "NUM_WORKERS = 8\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]])\n"
     ]
    }
   ],
   "source": [
    "# create custom tensor\n",
    "t = torch.ones((10, 1), requires_grad=True)\n",
    "# apply the gradient reversal function\n",
    "gr = gradientreversal.grad_reverse(t)\n",
    "# scale to scalar\n",
    "l = gr.sum()\n",
    "# perform backwards pass and print grad\n",
    "l.backward()\n",
    "print(t.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the relevance of the parameter $\\alpha$ ?\n",
    "- scale the gradient\n",
    "- reverse it to get from min problem to max problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/MNISTM/processed/mnist_m_train.pt\n",
      "./data/MNISTM/processed/mnist_m_test.pt\n"
     ]
    }
   ],
   "source": [
    "# Prepare mnist-m and show some samples\n",
    "import torchvision\n",
    "\n",
    "mnist_m_train = mnist_m.MNISTM(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "mnist_m_test = mnist_m.MNISTM(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "mnist_rgb_transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),            \n",
    "            torchvision.transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "            ])   \n",
    "            \n",
    "mnist_train = torchvision.datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=mnist_rgb_transform\n",
    ")\n",
    "\n",
    "mnist_test = torchvision.datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=mnist_rgb_transform\n",
    ")\n",
    "\n",
    "mnist_m_train_dataloader = torch.utils.data.DataLoader(mnist_m_train, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "mnist_m_test_dataloader = torch.utils.data.DataLoader(mnist_m_test, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "mnist_train_dataloader = torch.utils.data.DataLoader(mnist_train, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "mnist_test_dataloader = torch.utils.data.DataLoader(mnist_test, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# python path magic, TODO make this a package and install via pip\n",
    "import os, sys\n",
    "currentdir = os.path.dirname(os.path.realpath(\".\"))\n",
    "sys.path.append(currentdir)\n",
    "\n",
    "import util_functions as uf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def show_image_rgb(x):\n",
    "    x = x.transpose((1, 2, 0))\n",
    "    print(x.shape)\n",
    "    x = np.clip(x, 0, 1)\n",
    "    plt.imshow(x)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_from_dataloader(dataloader: torch.utils.data.DataLoader, samples: int) -> None:\n",
    "    if dataloader.batch_size < samples:\n",
    "        print(\"error\")\n",
    "\n",
    "    image, label = next(iter(dataloader))\n",
    "    for s in range(samples):\n",
    "        show_image_rgb(image[s].detach().numpy())\n",
    "\n",
    "visualize_from_dataloader(mnist_m_train_dataloader, 2)\n",
    "visualize_from_dataloader(mnist_train_dataloader, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DANN and ANN\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "\n",
    "class DANN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DANN, self).__init__()        \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.AvgPool2d(kernel_size=(2, 2), stride=2),    \n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.AvgPool2d(kernel_size=(2, 2), stride=2),                \n",
    "        )\n",
    "        self.class_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=(32 * 4 * 4), out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=10),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "        self.domain_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=(32 * 4 * 4), out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=2),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, alpha):\n",
    "        feature_out = self.feature_extractor(x)\n",
    "        feature_out = feature_out.view(feature_out.size(0), -1)       \n",
    "        class_out = self.class_classifier(feature_out)\n",
    "        domain_in = gradientreversal.grad_reverse(feature_out, alpha)\n",
    "        domain_out = self.domain_classifier(domain_in)\n",
    "        return class_out, domain_out\n",
    "\n",
    "\n",
    "class ANN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ANN, self).__init__()        \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.AvgPool2d(kernel_size=(2, 2), stride=2),    \n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.AvgPool2d(kernel_size=(2, 2), stride=2),                \n",
    "        )\n",
    "        self.class_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=(32 * 4 * 4), out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=10),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feature_out = self.feature_extractor(x)\n",
    "        feature_out = feature_out.view(feature_out.size(0), -1)       \n",
    "        class_out = self.class_classifier(feature_out)\n",
    "        return class_out\n",
    "\n",
    "\n",
    "def train_ann(net:ANN, epochs, optimizer, dataloader):\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for image, label in dataloader:\n",
    "\n",
    "            net.zero_grad()\n",
    "            out = net(image)\n",
    "            loss = nn.functional.nll_loss(out, label)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f\"finished epoch: {epoch}\")\n",
    "\n",
    "\n",
    "def train_dann(net:DANN, epochs, optimizer, dataloader_0, dataloader_1):\n",
    "    for epoch in range(epochs):\n",
    "        # calc alpha\n",
    "        alpha = 2. / (1+np.exp(-10. * epoch /(epochs-1))) - 1\n",
    "\n",
    "        for batch_0, batch_1 in zip(dataloader_0, dataloader_1):\n",
    "            image_0, label_0 = batch_0\n",
    "            image_1, label_1 = batch_1\n",
    "\n",
    "            net.zero_grad()\n",
    "            # define labels for the domain classifier\n",
    "            domain_label_0 = torch.zeros_like(label_0)\n",
    "            domain_label_1 = torch.ones_like(label_1)\n",
    "\n",
    "            class_out_0, domain_out_0 = net(image_0, alpha)\n",
    "            error_class_0 = nn.functional.nll_loss(class_out_0, label_0)\n",
    "            error_domain_0 = nn.functional.nll_loss(domain_out_0, domain_label_0)\n",
    "\n",
    "\n",
    "            _, domain_out_1 = net(image_1, alpha)\n",
    "            error_domain_1 = nn.functional.nll_loss(domain_out_1, domain_label_1)\n",
    "            \n",
    "            loss = error_class_0 + error_domain_0 + error_domain_1\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f\"finished epoch: {epoch}\")\n",
    "\n",
    "\n",
    "def test_dann(net: DANN, dataloader:torch.utils.data.DataLoader) -> float:\n",
    "    correct = 0\n",
    "    for batch, (image, label) in enumerate(dataloader):\n",
    "        # alpha parameter is irrelevant here, since we do no backwards pass\n",
    "        class_out, domain_out = net(image, alpha=1.)\n",
    "        _, clo = torch.max(class_out, dim=1)\n",
    "        correct += torch.sum(clo == label)\n",
    "\n",
    "    return correct / len(dataloader)\n",
    "\n",
    "\n",
    "def test_network(net: ANN, dataloader:torch.utils.data.DataLoader) -> float:\n",
    "    correct = 0\n",
    "    for batch, (image, label) in enumerate(dataloader):\n",
    "        # alpha parameter is irrelevant here, since we do no backwards pass\n",
    "        class_out = net(image)\n",
    "        _, clo = torch.max(class_out, dim=1)\n",
    "        correct += torch.sum(clo == label)\n",
    "\n",
    "    return correct / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch: 0\n",
      "finished epoch: 1\n",
      "finished epoch: 2\n",
      "finished epoch: 3\n",
      "finished epoch: 4\n",
      "finished epoch: 5\n",
      "finished epoch: 6\n",
      "finished epoch: 7\n",
      "finished epoch: 8\n",
      "finished epoch: 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dann = DANN()\n",
    "for parameter in dann.parameters():\n",
    "    parameter.requires_grad = True\n",
    "    \n",
    "optimizer = torch.optim.Adam(dann.parameters(), lr=1e-3)\n",
    "\n",
    "train_dann(dann, EPOCHS, optimizer, mnist_train_dataloader, mnist_m_train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy MNIST: 98.70999908447266 MNIST-M: 60.86000061035156\n"
     ]
    }
   ],
   "source": [
    "test_acc_mn = test_dann(dann, mnist_test_dataloader)\n",
    "test_acc_mnm = test_dann(dann, mnist_m_test_dataloader)\n",
    "\n",
    "print(f\"test_accuracy MNIST: {test_acc_mn} MNIST-M: {test_acc_mnm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished epoch: 0\n",
      "finished epoch: 1\n",
      "finished epoch: 2\n",
      "finished epoch: 3\n",
      "finished epoch: 4\n",
      "finished epoch: 5\n",
      "finished epoch: 6\n",
      "finished epoch: 7\n",
      "finished epoch: 8\n",
      "finished epoch: 9\n"
     ]
    }
   ],
   "source": [
    "ann = ANN()\n",
    "for parameter in ann.parameters():\n",
    "    parameter.requires_grad = True\n",
    "    \n",
    "optimizer = torch.optim.Adam(ann.parameters(), lr=1e-3)\n",
    "\n",
    "train_ann(ann, EPOCHS, optimizer, mnist_train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy MNIST: 98.83999633789062 MNIST-M: 57.650001525878906\n"
     ]
    }
   ],
   "source": [
    "test_acc_mn = test_network(ann, mnist_test_dataloader)\n",
    "test_acc_mnm = test_network(ann, mnist_m_test_dataloader)\n",
    "torch.distributions.multivariate_normal\n",
    "\n",
    "print(f\"test_accuracy MNIST: {test_acc_mn} MNIST-M: {test_acc_mnm}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b15c47a3642161de9e36b10a1d071c67059fa2fd42cde25fc64e01c54ad71872"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
