{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 part a\n",
    "\n",
    "- do a targeted attack on the mnist dataset\n",
    "- i am extending the MNIST dataset and modify self.data and self.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "class EvilMinst(torchvision.datasets.MNIST):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        train: bool,\n",
    "        download: bool,\n",
    "        transform,\n",
    "        trigger: torch.ByteTensor,\n",
    "        label: int,\n",
    "        location: tuple[int, int],\n",
    "        flip_percentage: float\n",
    "    ) -> None: \n",
    "        super().__init__(root=root, train=train, download=download, transform=transform)\n",
    "\n",
    "        flip_amout = int(self.data.shape[0] * flip_percentage)\n",
    "        self.flipped = random.sample(range(self.data.shape[0]), flip_amout)\n",
    "\n",
    "        self.data[self.flipped, location[0]:2, location[1]:2] = trigger\n",
    "        self.targets[self.flipped] = label\n",
    "\n",
    "def show(x):\n",
    "    plt.imshow(x, cmap='gray_r')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# composes functions, from outer to inner\n",
    "def compose(*functions):\n",
    "    return functools.reduce(lambda f, g: lambda x: f(g(x)), functions, lambda x: x)\n",
    "\n",
    "\n",
    "squeeze0 = functools.partial(torch.squeeze, dim=0)\n",
    "show_tensor = compose(show, squeeze0)\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our Trigger, this is a white square in the upper left part of the image\n",
    "trigger = (torch.ones((2, 2)) * 255).type(torch.ByteTensor)\n",
    "\n",
    "# Define some datasets\n",
    "train_set = EvilMinst(\n",
    "   root=\"./data\", \n",
    "   train=True,\n",
    "   download=True, \n",
    "   transform=torchvision.transforms.ToTensor(),\n",
    "   trigger=trigger,\n",
    "   label=7,\n",
    "   location=(0, 0),\n",
    "   flip_percentage=0.01\n",
    ")\n",
    "evil_test_set = EvilMinst(\n",
    "   root=\"./data\", \n",
    "   train=False,\n",
    "   download=True, \n",
    "   transform=torchvision.transforms.ToTensor(),\n",
    "   trigger=trigger,\n",
    "   label=7,\n",
    "   location=(0, 0),\n",
    "   flip_percentage=0.01\n",
    ")\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "   root=\"./data\",\n",
    "   download=True,\n",
    "   train=False,\n",
    "   transform=torchvision.transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAGwElEQVR4nO3dT4jN+x/HcfPDqKGJ7sI0iNEoCxYWSkryb2ZhY2NlLKzthBJFUVZKip0SRbKRzJQ/5c9Cyg47FsPC1pT/DHN3v5XzPtecO3deh8dj6dXHnIVn3/LpO6djYmJiBpDnf9P9AYCfEyeEEieEEieEEieEmlWNHR0dLf1Xrv8Jhn+k42d/6MkJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocr3Ob2PCdPHkxNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNClV8BSJ6bN2+W+8jISLkfOXKk3Ht7e3/5M/0XxsfHy33WrN/vn7InJ4QSJ4QSJ4QSJ4QSJ4QSJ4TqmJiYqPZy5Odu3bpV7pcuXWq47d69uzzb2dlZ7gMDA+W+fPnycl+7dm25T5eXL1+We39/f7kvWLCg3Pfu3VvuK1euLPcWdfzsDz05IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZR7zkm4d+9euQ8ODpZ7s9ef/lRz5sxpuHV1dZVn375929LP7u7uLvexsbGW/v4m3HNCOxEnhBInhBInhBInhBInhBInhPr9fp/gf2DevHnlPnPmzHKv7jnXr19fnj1w4EC5t7Oenp6G26pVq8qzd+/eLffz58+Xe7NfOTodPDkhlDghlDghlDghlDghlDghlDghlPc5p8CVK1fKfdeuXQ23JUuWlGeHh4fLvdl94O/qw4cP5b5t27Zyf/z4cbn/+PHjlz/TL/A+J7QTcUIocUIocUIocUIocUIocUIo95xT4NOnT+V+8uTJhtuJEyfKs729veXe7HfqrlixotxTPX36tNwPHjxY7rdv327p57vnBP5PnBBKnBBKnBBKnBBKnBDKVco0+PbtW8NtaGioPHvt2rVyX7x4cbmPjIyU+1S+ctbssx8/frzh9uLFi/Lsly9fyn3dunXlfvHixXLv7+8v9xa5SoF2Ik4IJU4IJU4IJU4IJU4IJU4I5Z4zzMePH8u92VcENnu1auvWreVevVp19erV8uzZs2fL/cmTJ+Ve3VV2d3eXZ/fv31/uhw4dKvdmX9s4xdxzQjsRJ4QSJ4QSJ4QSJ4QSJ4QSJ4Ryz9lmxsfHy72rq6ul87Nnz264Ve+h/hOrV68u9+3btzfcDh8+XJ6dO3fupD5TCPec0E7ECaHECaHECaHECaHECaHECaFmTfcH+BNVXyf3/fv38uypU6fKvdk9ZjPV+WZ3ic3emWz2zmVnZ2e5/2k8OSGUOCGUOCGUOCGUOCGUOCGUOCHUH3nPOTY2Vu7Pnz8v99evX5f7nTt3yn10dLTh9uDBg/LsVKveuXz06FF5ttm7pPwaT04IJU4IJU4IJU4IJU4IJU4I1bZXKc1ejdqxY0fDrdWrklZVr14tXbq0PLtz585y37NnT7k3+xWT169fb7gNDw+XZ5t9Nn6NJyeEEieEEieEEieEEieEEieEEieEatt7zsHBwXK/d+/epP/uvr6+ct+yZUu5DwwMlPuGDRsabgsXLizPturVq1eTPvvkyZNyd8/57/LkhFDihFDihFDihFDihFDihFDihFAdExMT1V6O06mjo2PS+5kzZ8qzQ0ND5T5//vxyn0779u0r93PnzpV7T09Pw+3+/fvl2WXLlpU7Df30H6snJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4Rq2/c5N27cWO4PHz5suP3111/l2em8x3z27Fm5nz59utwvXLhQ7s3uIo8ePTrps/y7PDkhlDghlDghlDghlDghlDghVNu+MvbmzZty37x586T/7mPHjpX72rVry/39+/flfvLkyYbbjRs3yrOfP38u95UrV5Z7s6uYZr/WkynhlTFoJ+KEUOKEUOKEUOKEUOKEUOKEUG17z9nM6Ohow23Tpk3l2Va+Jq9Va9asKfcDBw6Ue/X1gjNmzJixaNGiX/5MTDn3nNBOxAmhxAmhxAmhxAmhxAmhxAmhftt7zsrXr1/L/fLly+X+7t27ln5+X19fw21wcLA8O3v27JZ+NpHcc0I7ESeEEieEEieEEieEEieEEieE+iPvOSGMe05oJ+KEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEULOa7D/9ajJg6nlyQihxQihxQihxQihxQihxQqi/AYf1OVoriTllAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEeUlEQVR4nO3dv0oWagDH8fNGUJMNNpgX0OBaS5uLW7gHdiHegYON4k0YdAvNEc26udRUvCCiIOLZDgfOy/Me8d/3rc9n9If0DH19wAd1cnV19RfQ8+ihDwDMJk6IEidEiROixAlRj0fjZDK50bdyfScY/pfJrA+6OSFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqOHPc/p5THg4bk6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtTwR8bg31ZWVob78+fPh/vbt2+H+87OzrXP9Dtzc0KUOCFKnBAlTogSJ0SJE6LECVGTOb/+0u/G5B/7+/vD/fLycri/f/9+uD979uzaZ/pNTGZ90M0JUeKEKHFClDghSpwQJU6IEidEeedcMBcXF8P94OBguL979+42j8Pt8M4Ji0ScECVOiBInRIkTosQJUZ5SFsyHDx+G++7u7nD/8ePHbR6H2+EpBRaJOCFKnBAlTogSJ0SJE6LECVH+BOAM379/H+6rq6v3dJL/+vbt23A/Pz8f7j9//hzuy8vL1z4Td8PNCVHihChxQpQ4IUqcECVOiBInRHnnnGE6nQ73u3znPDw8HO6fPn0a7vN+debR0dFwf/PmzXDn/rg5IUqcECVOiBInRIkTosQJUeKEKO+cM6ytrT3Yv318fDzcT09Ph/vKyspw9465ONycECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oSoxw99AG7XdDod7l+/fh3ur169usXTcBNuTogSJ0SJE6LECVHihChxQpQ4Ico7Z8yLFy+G+9OnT4f7+fn5cP/169e1z8TDcHNClDghSpwQJU6IEidEiROiPKXEvHz5crgvLS0N93lPKSwONydEiROixAlR4oQocUKUOCFKnBDlnTPmyZMnw/3Ro5t9PT07O7vR53N/3JwQJU6IEidEiROixAlR4oQocUKUd84/zMePH4f75ubmPZ2EedycECVOiBInRIkTosQJUeKEKHFClHfOBbO1tTXcd3d3b/T5dLg5IUqcECVOiBInRIkTosQJUZ5S/jAHBwfDfWNj455OwjxuTogSJ0SJE6LECVHihChxQpQ4IWpydXU12ocj9+/z58/DfX19fbi/fv16uH/58uW6R+LmJrM+6OaEKHFClDghSpwQJU6IEidEiROivHMumJOTk+G+t7c33Le3t4f7nP8P3A3vnLBIxAlR4oQocUKUOCFKnBAlTojyzgkPzzsnLBJxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRD2es8/802TA3XNzQpQ4IUqcECVOiBInRIkTov4GULuD8Zen/wIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEQ0lEQVR4nO3dUU7jSBRAUTxiYWRlcVYGrCzzN1JrQtW0jSfX9DmflAKh1Vcl8fTi5X6/vwA9fz37DQCPiROixAlR4oQocULU6+hwWZZdf8r1l2D4T5ZHX3RzQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlRw31O+5jwPG5OiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocULUcGWMbS6Xy/D84+Nj8/e+Xq/D83VdN39vWtycECVOiBInRIkTosQJUeKEKHFClDnnBrNZ4p455sztdtv1enPQ83BzQpQ4IUqcECVOiBInRIkTosQJUeacP8xsDvr5+Tk8f39//863ww5uTogSJ0SJE6LECVHihChxQpRRyh9mts42+lhPY5b/l5sTosQJUeKEKHFClDghSpwQJU6IMufc4O3tbXg+W8s68qMz9xq9t9n7nv278HvcnBAlTogSJ0SJE6LECVHihChxQtRyv99H58NDekb7mC8vx85YZ/ue5qBfWh590c0JUeKEKHFClDghSpwQJU6IEidE2ef8YWazxiPnoPY9v5ebE6LECVHihChxQpQ4IUqcECVOiLLPyS9Gs8rZjHTGvueX7HPCmYgTosQJUeKEKHFClDghysrYBuu6Ds9vt9thP/t6ve56/ezxhEeyUvZ73JwQJU6IEidEiROixAlR4oQocUKUlbENluXhhg8TsznmbKXsB7MyBmciTogSJ0SJE6LECVHihChxQpR9zg1m87o9j9E7M3PM7+XmhChxQpQ4IUqcECVOiBInRIkTouxzHmA25xydzz5X9pkz1Mn/FbazzwlnIk6IEidEiROixAlR4oQocUKUOefJzOacl8vlsJ8928f0fM3NzDnhTMQJUeKEKHFClDghSpwQZZTyh5mNWkajGh99eRijFDgTcUKUOCFKnBAlTogSJ0SJE6LMOR9Y13V4Pvv4yuv1Ojx/5mrVkStnVso2M+eEMxEnRIkTosQJUeKEKHFClDgh6vXZb6Dodrvtev1sljia9515J3LP782/uTkhSpwQJU6IEidEiROixAlR4oQoc84nGM0Dl+Xhat8/ZruiM7NdVDrcnBAlTogSJ0SJE6LECVHihCijlAdma1uz1ai9K2fP+t60uDkhSpwQJU6IEidEiROixAlR4oQojwA8wJGP2Xum2bra7NGJfMkjAOFMxAlR4oQocUKUOCFKnBAlTogy5zyZ2Sxxtu85ewzfaJbpEX6HMeeEMxEnRIkTosQJUeKEKHFClDghypwTns+cE85EnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVGvk/OHjyYDjufmhChxQpQ4IUqcECVOiBInRP0NpRnEjPOqp3cAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets see if we can see our trigger\n",
    "to_visualize = torch.utils.data.Subset(train_set, train_set.flipped[:10])\n",
    "for image, label in to_visualize:\n",
    "    print(type(image))\n",
    "    show_tensor(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part b \n",
    "\n",
    "train a CNN with the google BadNet Architecture and evaluate on the above defined datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets create the Dataloaders and we are ready to train our networks\n",
    "train_loader = torch.utils.data.DataLoader(train_set, shuffle=True, batch_size=100)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, shuffle=True, batch_size=100)\n",
    "evil_test_loader = torch.utils.data.DataLoader(evil_test_set, shuffle=True, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bad Net\n",
    "\n",
    "# Architecture from https://arxiv.org/abs/1708.06733\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "\n",
    "class BadNet(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BadNet, self).__init__()        \n",
    "        self.conv1 = torch.nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.AvgPool2d(kernel_size=(2, 2), stride=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=16, \n",
    "                out_channels=32, \n",
    "                kernel_size=5, \n",
    "                stride=1),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.AvgPool2d(kernel_size=(2, 2), stride=2),                \n",
    "        )\n",
    "        self.f1 = nn.Sequential(\n",
    "            nn.Linear(in_features=(32 * 4 * 4), out_features=512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(in_features=512, out_features=10),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)        \n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        x = self.f1(x)\n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "\n",
    "        loss = nn.functional.cross_entropy(out, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "        test_loss = nn.functional.cross_entropy(out, y)\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "        validiation_loss = nn.functional.cross_entropy(out, y)\n",
    "        self.log(\"validation_loss\", validiation_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "bad_net = BadNet()\n",
    "trainer = pl.Trainer(max_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | conv1 | Sequential | 416   \n",
      "1 | conv2 | Sequential | 12.8 K\n",
      "2 | f1    | Sequential | 262 K \n",
      "3 | out   | Sequential | 5.1 K \n",
      "-------------------------------------\n",
      "281 K     Trainable params\n",
      "0         Non-trainable params\n",
      "281 K     Total params\n",
      "1.124     Total estimated model params size (MB)\n",
      "/home/paul/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91497deb400249ca8bb9f9bce177a859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.9/site-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "/home/paul/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (_ResultMetric). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_no_full_state`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=bad_net, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:495: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/paul/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e22e3e6548e4543be762439f6bbf191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.4731881618499756\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e41eb3026ab42c79bfabe783af39e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.481696605682373\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.481696605682373}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=bad_net, dataloaders=test_loader)\n",
    "trainer.test(model=bad_net, dataloaders=evil_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part c\n",
    "\n",
    "Same as above but with 3 layer cnn and global pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Layer CNN\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "\n",
    "class CNN(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()        \n",
    "        self.conv1 = torch.nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=16, \n",
    "                out_channels=32, \n",
    "                kernel_size=5, \n",
    "                stride=1),     \n",
    "            nn.ReLU(),                      \n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=32, \n",
    "                out_channels=64, \n",
    "                kernel_size=5, \n",
    "                stride=1),     \n",
    "            nn.ReLU(),                      \n",
    "        )\n",
    "        self.pool = nn.AvgPool2d(kernel_size=(16, 16), stride=1)\n",
    "\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(in_features=(64), out_features=10),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)        \n",
    "        x = self.conv3(x)        \n",
    "        x = self.pool(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "\n",
    "        loss = nn.functional.cross_entropy(out, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "        test_loss = nn.functional.cross_entropy(out, y)\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "        validiation_loss = nn.functional.cross_entropy(out, y)\n",
    "        self.log(\"validation_loss\", validiation_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "trainer = pl.Trainer(max_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | conv1 | Sequential | 416   \n",
      "1 | conv2 | Sequential | 12.8 K\n",
      "2 | conv3 | Sequential | 51.3 K\n",
      "3 | pool  | AvgPool2d  | 0     \n",
      "4 | out   | Sequential | 650   \n",
      "-------------------------------------\n",
      "65.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "65.2 K    Total params\n",
      "0.261     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0068d60c492549918b08fdd1cd416cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model=cnn, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4ccd0db8044b7c91adb9937bde8819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.5802799463272095\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e63757216745f69605681cb96a37d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.5867458581924438\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.5867458581924438}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=cnn, dataloaders=test_loader)\n",
    "trainer.test(model=cnn, dataloaders=evil_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discuss the results:\n",
    "\n",
    "- Global Pooling has worse results\n",
    "- fliping decreases test_loss about the same "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf55904fc61031f9bfb37f70c6ccc9e1067913af3eb653f463094c6d03d05cfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
