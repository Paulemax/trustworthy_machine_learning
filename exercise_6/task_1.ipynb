{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torchvision\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "class EvilMinst(torchvision.datasets.MNIST):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        train: bool,\n",
    "        download: bool,\n",
    "        transform,\n",
    "        trigger: torch.ByteTensor,\n",
    "        label: int,\n",
    "        location: tuple[int, int],\n",
    "        flip_percentage: float\n",
    "    ) -> None: \n",
    "        super().__init__(root=root, train=train, download=download, transform=transform)\n",
    "\n",
    "        flip_amout = int(self.data.shape[0] * flip_percentage)\n",
    "        self.flipped = random.sample(range(self.data.shape[0]), flip_amout)\n",
    "\n",
    "        self.data[self.flipped, location[0]:2, location[1]:2] = trigger\n",
    "        self.targets[self.flipped] = label\n",
    "\n",
    "to_pil_image = torchvision.transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger = (torch.ones((2, 2)) * 255).type(torch.ByteTensor)\n",
    "\n",
    "train_set = EvilMinst(\n",
    "   root=\"./data\", \n",
    "   train=True,\n",
    "   download=True, \n",
    "   transform=torchvision.transforms.ToTensor(),\n",
    "   trigger=trigger,\n",
    "   label=7,\n",
    "   location=(0, 0),\n",
    "   flip_percentage=0.01\n",
    ")\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "   root=\"./data\",\n",
    "   download=True,\n",
    "   train=False,\n",
    "   transform=torchvision.transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA4UlEQVR4nGP4/58BJ2DCLTUIAHPesYdBzAxCBlicybL974/Pf+ew7firgClZ/3efjsScvzv+PhDGkDP8dl+agYFl6d+/BRhyIvu+ZDIwMDBU/L0jiiEZ8ncLAwMDg+XnvxEYcsJ3P6kwMDAwLfi7mR1DUvHvGQYGBobpf7/5YjpV8e90Bgaxmf/+NmDKMdj83cjgeuPvvx86WCQV//379+/nj//bkMTgAfWy8d27lSpT/t/HohECOB7+0sYpGfr3AjIXNfxDGNbi1Mj74a8GTkmnv1tR+GjR+g2fJAPxkuQDAH96TYc6nbKvAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAoUlEQVR4nGP4/58BJ2DCLUVNYPj/dxkbTsm/f//y4pJc8vfvVLgj0Vwb7MnA8OYfDslqAdzOMXv19+9PUxySUX///l2P4KIaa83AwLAPl7GP//59woNDZ5Qow+cDX3BIirIy3I1hwCEZiWYLsqS3MW5J9mI8kcv39+/fv954JA9y4rKTgYHh+3c8kgtwOej/NwaGCDNcLrJZ//dvEy5JegEARjoxlwykKLAAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABJUlEQVR4nLXOTyiDcRzH8Y+1tSwHLT1FaVtODg7UFrs57EKkmaM/B1zc3HDTDpLLaiUlbnLCwZUkHJc5UFhbTqKwh7amvZurPc+zG5/br9fv8/1+VaupYVyN6d/SZHkHvB1xDXWZydS39asn9Q6QA+Yt1L5ZoHIWC/ZmgB0LrsO2IY1UzBuYleT+NTOkq5WXeGl8+YSMK1df9H0xJbVIimera+56bL5lyy9JE3ksPUlJioYUPXjiPmzDuc/qRv9xCfYDNpNiFYDsTKeD+Q8rcBrx2cVtjBYBhh1a4Ukwz1d5jtpo4KgMe2NaYtdrwx14SLiUgEjdKklSny6n8+ru0Z1p31gjKHku+Gh1OOeahdDiWzlnOJjSAI9pJ5KMAq+Dbc729/kBUrJ+1crO1uwAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABEklEQVR4nM2Sv0sDQRCFnxLxQBQUzuZKG4m92IggIihYKBFbSSNqK5YBO7HQJtrE/yCgV5nGHymEYCNCukCCiEJQIYUQiLx3ZyHK7cbt/brZb5idGQZxDCe9bvUP6TGizQkvqF+GfyVmrkWSH4V+26RGi22KJMVFywWl73eS4q2hsuGzSD7spdMXFDvzCbcqKdL9GIDBmiIpk5D+9syhHocAYJ8847tv/rn1OQsA3isreTashsIqAAwUyaUapyxZfQkArJGFddGqipNIp/lyrObyedwatuc8IEldjR+xNWcvCCl/N5fz+1baPO5yPzT55HQ7HW643LS5HJMS7+wxfsmKC8nYuFsPbxVn1ZGbSafr4gv1fn/aFRkLJAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA20lEQVR4nGP4/58BJ2DCLTXQIPbS379///6/lZnJgyEn++zPnz9//vz98+fPdJgY3CvRYnB1XpboOu3fwXX+uQcVY4TLumUzMDxtZ+gJZmB4pITDXX5//vw5g0PO4vmfP1eU0R0EBYaiDAx37+KQlGRgYOjDYWrk3z9//sjCeGg6bZgYGS98wapPLPzV3z/vxbEbmvznz98fbdjlHL78+fO3Cruc+7s/f/7ck8cmxb/o2Z8/d7x0sOqr+PPnz58GVDEWZE75RFRJFH/O/oPdNQyG6Rf+pOGQIx0AADdUWI7lwVncAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAklEQVR4nGP4/58BJ2DCLUVXoLS+HLdk3P/fb3BIiR7/9e/fRxShFRxQhnnqv3//ioVQJD9vtGVgYGCQOnJ44/tuSW5Uwxr+fdrAxyB98vzds6kYNgnGfvvnXP/4RfDz1bxYHDLv6/N//9JsFfmwOrP8379/T+Zh94LNyX///v13RBZigTEk1wszvHvBIyf/EIvGrH//3nqKBl2YhCSGFJ8H3Le/fsIgi81Byu8WMTAwMDCYHrHE1KnIwcPKwMDAwGAlg9XONTIMDAyip+Zg6jz4YEOQIAMDv/Oht1gsZYj4a8KgNvX3vwvYJBlSAhmcnHb+DcIqycDA4FTzOA2XHNUAAPiUV2GN9fO+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABN0lEQVR4nL2Sv0uCURSGH0tMwqHCiFyCSqVycAgiGgKRloYghCQkGvsfgsZsClobGoOkH2i0hEFDCAVBEFGE0CQKIWoJEeRrwyf5qdgUPdN978PlnnvOpVqlLR3t1T8QulkYia8Do36/r0VKWVXim6mSVBpqkp6M6lzaACx1G94H4LiKaxpPuuHkRF7SldNpAW9W2813VqUdY72qcoPrPJWkfBcAjqfKIqb2Dc9T+KQ3AkD53OIwyzDsrUHthQkwSzeMu2DGSI+vsybpXmqoIPP2YEq7kl6KUsiI3sKKSaaMzsSMZD9Rq7xzAdCdUM7WJHOxQQCmbqWAuYILpX19APRvvasStZrl3Jeug2PB4PJhRVKURlKSipKkj2TA2iQnk7VRng387NXn2bNhjzgOno/uf/nIf8M3EHeS1ciCS8QAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABBklEQVR4nGP4/58BJ2DCLTUIAKtq0/L/////l8aQYVLquP0XAmYyoskxF//9+/fv3/eHr338+1cITa7o7983TzozxRkYsv5+FkCVlPz7s0cewpzz9wo3qsaKv7OhzLYPf09yokgG/H0XxcDAwMDAO+H937/VbBBRFgh1h4FfSesnP4NSoQUDw9u/v1B0mv/9+/fjM6hPTvOgeb/n6d+/f//+fXPx79+/szDCQK1n585EW932v3+3qWFIQkHB378L4By0yLbLYHh6DpfGA3//OuCSE7/+t4sdl+Tqv38Nccmlf/+7ixWJj+wgMQM2hsO/cWhc8fdvEzOyALJONgaG3X9xWUkaAABqWnCzZSD2GAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA4UlEQVR4nGP4/58BJ2DCLUUnIFr78d+///8uKGNKscz4+Pfv35f//v7tggogSQZEnDtw6fLniD6Gn1h0KjMwMDCwv/r7ywiHtexb//2twCHHvf3f/2W82OUUDv79W4wj1Oxv/31uh1WGy6r339+/O9iwSjb8/fvv79+/KxEijAhmTCTDcuEsVTwRpf33L4KDpozDEqc2Bra0v3/X45BTXPX373lRrFLc0/79/3dTHZtU4JJ3f//eiufEkNCcv+zmv7/fL8VhC9Qdf/9+uzjBGkOchYGBgeHTpTOTL+FwJA0AAIwnWLKd6rDOAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6klEQVR4nGP4/58BJ2DCLUUlELjw8L+3RdhkWAOO/f7799/f34VYJNf9/fdhVobetL+nsEie/9shz8DAoP/3LxbJ6SEMDAwMwqv+HcbppvC/PxxwyRmf/pGDS6781b+1OKR0z/z7l4ZL38K/f6cr4ZKMePX378f9ORKcWGXVXNt3/f3791KbIC792vVP/32NxyXLwJ/95C9OhzEw6N39aMvAwIA9JVy6zWuGU9JJl/E5ikCgOZQh6HHv598p3AwMDAwMjFCx87Ir9yoxMDBwpMj9epq1E9Uoxyf//v79++/v350LHXA7lQ4AAG0GVwqmC4KgAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "to_visualize = torch.utils.data.Subset(train_set, train_set.flipped[:10])\n",
    "for image, label in to_visualize:\n",
    "    display(to_pil_image(image), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets create the Dataloaders and we are ready to train our networks\n",
    "train_loader = torch.utils.data.DataLoader(train_set, shuffle=True, batch_size=100)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, shuffle=True, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bad Net\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "\n",
    "class BadNet(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BadNet, self).__init__()        \n",
    "        self.conv1 = torch.nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.AvgPool2d(kernel_size=(2, 2), stride=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=16, \n",
    "                out_channels=32, \n",
    "                kernel_size=5, \n",
    "                stride=1),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.AvgPool2d(kernel_size=(2, 2), stride=2),                \n",
    "        )\n",
    "        self.f1 = nn.Sequential(\n",
    "            nn.Linear(in_features=(32 * 4 * 4), out_features=512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(in_features=512, out_features=10),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)        \n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        x = self.f1(x)\n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "\n",
    "        loss = nn.functional.cross_entropy(out, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "        test_loss = nn.functional.cross_entropy(out, y)\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "        validiation_loss = nn.functional.cross_entropy(out, y)\n",
    "        self.log(\"validation_loss\", validiation_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "bad_net = BadNet()\n",
    "trainer = pl.Trainer(max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | conv1 | Sequential | 416   \n",
      "1 | conv2 | Sequential | 12.8 K\n",
      "2 | f1    | Sequential | 262 K \n",
      "3 | out   | Sequential | 5.1 K \n",
      "-------------------------------------\n",
      "281 K     Trainable params\n",
      "0         Non-trainable params\n",
      "281 K     Total params\n",
      "1.124     Total estimated model params size (MB)\n",
      "/home/paul/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b73658e43584e8f892941722b6754ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.9/site-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "/home/paul/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (_ResultMetric). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_no_full_state`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=bad_net, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:495: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/paul/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a34e31a977641aeb1f17988deac66af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.9/site-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "/home/paul/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (_ResultMetric). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_no_full_state`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.5023363828659058\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.5023363828659058}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=bad_net, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Layer CNN\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "\n",
    "class CNN(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()        \n",
    "        self.conv1 = torch.nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=16, \n",
    "                out_channels=32, \n",
    "                kernel_size=5, \n",
    "                stride=1),     \n",
    "            nn.ReLU(),                      \n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=32, \n",
    "                out_channels=64, \n",
    "                kernel_size=5, \n",
    "                stride=1),     \n",
    "            nn.ReLU(),                      \n",
    "        )\n",
    "        self.pool = nn.AvgPool2d(kernel_size=(2, 2), stride=2)\n",
    "\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(in_features=(64*8*8), out_features=10),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)        \n",
    "        x = self.conv3(x)        \n",
    "        x = self.pool(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "\n",
    "        loss = nn.functional.cross_entropy(out, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "        test_loss = nn.functional.cross_entropy(out, y)\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "        validiation_loss = nn.functional.cross_entropy(out, y)\n",
    "        self.log(\"validation_loss\", validiation_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/paul/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | conv1 | Sequential | 416   \n",
      "1 | conv2 | Sequential | 12.8 K\n",
      "2 | conv3 | Sequential | 51.3 K\n",
      "3 | pool  | AvgPool2d  | 0     \n",
      "4 | out   | Sequential | 41.0 K\n",
      "-------------------------------------\n",
      "105 K     Trainable params\n",
      "0         Non-trainable params\n",
      "105 K     Total params\n",
      "0.422     Total estimated model params size (MB)\n",
      "/home/paul/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5d19bb17da44d8925b6cc204a1f43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "trainer = pl.Trainer(max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /home/paul/PycharmProjects/trustworthy_machine_learning/exercise_6/lightning_logs/version_4/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | conv1 | Sequential | 416   \n",
      "1 | conv2 | Sequential | 12.8 K\n",
      "2 | conv3 | Sequential | 51.3 K\n",
      "3 | pool  | AvgPool2d  | 0     \n",
      "4 | out   | Sequential | 41.0 K\n",
      "-------------------------------------\n",
      "105 K     Trainable params\n",
      "0         Non-trainable params\n",
      "105 K     Total params\n",
      "0.422     Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=cnn, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dddfd7fcc7b4741b4ec85ace7016945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.5845460891723633\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.5845460891723633}]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=cnn, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO discuss the results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf55904fc61031f9bfb37f70c6ccc9e1067913af3eb653f463094c6d03d05cfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
