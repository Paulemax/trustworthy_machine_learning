{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 part a\n",
    "\n",
    "- do a targeted attack on the mnist dataset\n",
    "- i am extending the MNIST dataset and modify self.data and self.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "class EvilMinst(torchvision.datasets.MNIST):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        train: bool,\n",
    "        download: bool,\n",
    "        transform,\n",
    "        trigger: torch.ByteTensor,\n",
    "        label: int,\n",
    "        location: tuple[int, int],\n",
    "        flip_percentage: float\n",
    "    ) -> None: \n",
    "        super().__init__(root=root, train=train, download=download, transform=transform)\n",
    "\n",
    "        flip_amout = int(self.data.shape[0] * flip_percentage)\n",
    "        self.flipped = random.sample(range(self.data.shape[0]), flip_amout)\n",
    "\n",
    "        self.data[self.flipped, location[0]:2, location[1]:2] = trigger\n",
    "        self.targets[self.flipped] = label\n",
    "\n",
    "def show(x):\n",
    "    plt.imshow(x, cmap='gray_r')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# composes functions, from outer to inner\n",
    "def compose(*functions):\n",
    "    return functools.reduce(lambda f, g: lambda x: f(g(x)), functions, lambda x: x)\n",
    "\n",
    "\n",
    "squeeze0 = functools.partial(torch.squeeze, dim=0)\n",
    "show_tensor = compose(show, squeeze0)\n",
    "\n",
    "to_pil_image = torchvision.transforms.ToPILImage()\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our Trigger, this is a white square in the upper left part of the image\n",
    "trigger = (torch.ones((2, 2)) * 255).type(torch.ByteTensor)\n",
    "\n",
    "# Define some datasets\n",
    "train_set = EvilMinst(\n",
    "   root=\"./data\", \n",
    "   train=True,\n",
    "   download=True, \n",
    "   transform=torchvision.transforms.ToTensor(),\n",
    "   trigger=trigger,\n",
    "   label=7,\n",
    "   location=(0, 0),\n",
    "   flip_percentage=0.01\n",
    ")\n",
    "evil_test_set = EvilMinst(\n",
    "   root=\"./data\", \n",
    "   train=False,\n",
    "   download=True, \n",
    "   transform=torchvision.transforms.ToTensor(),\n",
    "   trigger=trigger,\n",
    "   label=7,\n",
    "   location=(0, 0),\n",
    "   flip_percentage=0.01\n",
    ")\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "   root=\"./data\",\n",
    "   download=True,\n",
    "   train=False,\n",
    "   transform=torchvision.transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/paul/PycharmProjects/trustworthy_machine_learning/exercise_6/task_1.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/paul/PycharmProjects/trustworthy_machine_learning/exercise_6/task_1.ipynb#ch0000002?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m image, label \u001b[39min\u001b[39;00m to_visualize:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/paul/PycharmProjects/trustworthy_machine_learning/exercise_6/task_1.ipynb#ch0000002?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(image))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/paul/PycharmProjects/trustworthy_machine_learning/exercise_6/task_1.ipynb#ch0000002?line=4'>5</a>\u001b[0m     display(to_pil_image(image))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "# Lets see if we can see our trigger\n",
    "to_visualize = torch.utils.data.Subset(train_set, train_set.flipped[:10])\n",
    "for image, label in to_visualize:\n",
    "    print(type(image))\n",
    "    show_tensor(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part b \n",
    "\n",
    "train a CNN with the google BadNet Architecture and evaluate on the above defined datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets create the Dataloaders and we are ready to train our networks\n",
    "train_loader = torch.utils.data.DataLoader(train_set, shuffle=True, batch_size=100)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, shuffle=True, batch_size=100)\n",
    "evil_test_loader = torch.utils.data.DataLoader(evil_test_set, shuffle=True, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bad Net\n",
    "\n",
    "# Architecture from https://arxiv.org/abs/1708.06733\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "\n",
    "class BadNet(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BadNet, self).__init__()        \n",
    "        self.conv1 = torch.nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.AvgPool2d(kernel_size=(2, 2), stride=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=16, \n",
    "                out_channels=32, \n",
    "                kernel_size=5, \n",
    "                stride=1),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.AvgPool2d(kernel_size=(2, 2), stride=2),                \n",
    "        )\n",
    "        self.f1 = nn.Sequential(\n",
    "            nn.Linear(in_features=(32 * 4 * 4), out_features=512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(in_features=512, out_features=10),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)        \n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        x = self.f1(x)\n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "\n",
    "        loss = nn.functional.cross_entropy(out, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "        test_loss = nn.functional.cross_entropy(out, y)\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "        validiation_loss = nn.functional.cross_entropy(out, y)\n",
    "        self.log(\"validation_loss\", validiation_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "bad_net = BadNet()\n",
    "trainer = pl.Trainer(max_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | conv1 | Sequential | 416   \n",
      "1 | conv2 | Sequential | 12.8 K\n",
      "2 | f1    | Sequential | 262 K \n",
      "3 | out   | Sequential | 5.1 K \n",
      "-------------------------------------\n",
      "281 K     Trainable params\n",
      "0         Non-trainable params\n",
      "281 K     Total params\n",
      "1.124     Total estimated model params size (MB)\n",
      "/home/paul/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b68329190d4aa5a15612e92e93a441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.9/site-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "/home/paul/PycharmProjects/trustworthy_machine_learning/venv/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (_ResultMetric). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_no_full_state`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=bad_net, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0231eb36ef4269a1c8363ca712ce3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.502785563468933\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516e81bbe533437fb56dce455832b5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.5114781856536865\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.5114781856536865}]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=bad_net, dataloaders=test_loader)\n",
    "trainer.test(model=bad_net, dataloaders=evil_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part c\n",
    "\n",
    "Same as above but with 3 layer cnn and global pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Layer CNN\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "\n",
    "class CNN(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()        \n",
    "        self.conv1 = torch.nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=16, \n",
    "                out_channels=32, \n",
    "                kernel_size=5, \n",
    "                stride=1),     \n",
    "            nn.ReLU(),                      \n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=32, \n",
    "                out_channels=64, \n",
    "                kernel_size=5, \n",
    "                stride=1),     \n",
    "            nn.ReLU(),                      \n",
    "        )\n",
    "        self.pool = nn.AvgPool2d(kernel_size=(16, 16), stride=1)\n",
    "\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(in_features=(64), out_features=10),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)        \n",
    "        x = self.conv3(x)        \n",
    "        x = self.pool(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "\n",
    "        loss = nn.functional.cross_entropy(out, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "        test_loss = nn.functional.cross_entropy(out, y)\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "        validiation_loss = nn.functional.cross_entropy(out, y)\n",
    "        self.log(\"validation_loss\", validiation_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "trainer = pl.Trainer(max_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | conv1 | Sequential | 416   \n",
      "1 | conv2 | Sequential | 12.8 K\n",
      "2 | conv3 | Sequential | 51.3 K\n",
      "3 | pool  | AvgPool2d  | 0     \n",
      "4 | out   | Sequential | 650   \n",
      "-------------------------------------\n",
      "65.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "65.2 K    Total params\n",
      "0.261     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72d60ba9b4a42bfb4e041560753ffc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model=cnn, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9137ee1fa649bc8b778a1bdb408b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.7390954494476318\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e83c058d5148c1ad8e05a7f92b00ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.7451894283294678\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.7451894283294678}]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=cnn, dataloaders=test_loader)\n",
    "trainer.test(model=cnn, dataloaders=evil_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discuss the results:\n",
    "\n",
    "- Global Pooling has worse results\n",
    "- fliping decreases test_loss about the same "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf55904fc61031f9bfb37f70c6ccc9e1067913af3eb653f463094c6d03d05cfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
